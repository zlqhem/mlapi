{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "dgvbqmqxBVki"
      ],
      "mount_file_id": "1ZSE9LiJhoGlCb7wTODFmuQfNpnnn6kuq",
      "authorship_tag": "ABX9TyNpdBZW41beXVabdn4G7h8R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zlqhem/mlapi/blob/main/aws-ecr-torchscript/aws_ecr_torchscript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# torchscript"
      ],
      "metadata": {
        "id": "xGdoe6EjzAdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load a model from S3"
      ],
      "metadata": {
        "id": "gEAcaOgxAj76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install boto3 python-dotenv"
      ],
      "metadata": {
        "id": "K09aNKDczTrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aws access key setup\n",
        "import dotenv\n",
        "# contains 'AWS_ACCESS_KEY', 'AWS_SCRET_ACCESS_KEY'\n",
        "env_file = \"/content/drive/MyDrive/w2/mlapi/aws.env\"\n",
        "dotenv.load_dotenv(env_file)"
      ],
      "metadata": {
        "id": "90-_mUNd00Ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554b0e8c-8048-4698-bd35-2c9fa7e6b92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import unzip_requirements\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import json\n",
        "from io import BytesIO\n",
        "import time\n",
        "import os\n",
        "import base64\n",
        "\n",
        "import boto3\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "\n",
        "s3 = boto3.client(\"s3\")\n",
        "bucket = \"soltware.test\"\n",
        "key = \"v1/best.torchscript\"\n",
        "\n",
        "def download_model(s3, bucket, key):\n",
        "    file_name = os.path.basename(key)\n",
        "    print ('file_name', file_name)\n",
        "    s3.download_file(bucket, key, file_name)\n",
        "\n",
        "\n",
        "def load_model(s3, bucket):\n",
        "  response = s3.get_object(Bucket=bucket, Key=key)\n",
        "  #state = torch.load(BytesIO(response[\"Body\"].read()))\n",
        "  #model.load_state_dict(state)\n",
        "  #model.eval()\n",
        "\n",
        "  bytes_array = BytesIO(response[\"Body\"].read())\n",
        "  model = torch.jit.load(bytes_array, map_location=torch.device('cpu')).eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "qGqhqb_EzEPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_model(s3, bucket, key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvB0-y010sqd",
        "outputId": "43c39e9b-4ebc-4be9-eb98-476585796359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_name best.torchscript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al best.torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mHwrQBd5m4d",
        "outputId": "a4a447e1-3bde-4656-f7a7-521a2c4dd762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 103561564 Feb 13 02:24 best.torchscript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!date"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHS-xane5p7O",
        "outputId": "c8c72cfd-98f0-4886-ac71-aade378c1cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  4 04:14:51 PM UTC 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(s3, bucket)"
      ],
      "metadata": {
        "id": "fqoOALMy6Gg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGSmv9JJ7OGi",
        "outputId": "b0fad226-9154-4f7c-f5a8-9b49296eadc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecursiveScriptModule(original_name=DetectionModel)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lambda handler"
      ],
      "metadata": {
        "id": "dgvbqmqxBVki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.array([\n",
        "  'Tomato Healthy',\n",
        "  'Strawberry Healthy',\n",
        "  'Lettuce Healthy',\n",
        "  'Strawberry Ashy Mold',\n",
        "  'Strawberry White Powdery Mildew',\n",
        "  'Lettuce Bacterial Head Rot',\n",
        "  'Lettuce Bacterial Wilt',\n",
        "  'Tomato Leaf Mold',\n",
        "  'Tomato Yellow Leaf Curl Virus',\n",
        "])\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    '''\n",
        "    if event.get(\"source\") in [\"aws.events\", \"serverless-plugin-warmup\"]:\n",
        "        print('Lambda is warm!')\n",
        "        return {}\n",
        "    '''\n",
        "\n",
        "    data = json.loads(event[\"body\"])\n",
        "    print(\"data keys:\", data.keys())\n",
        "    image = data[\"image\"]\n",
        "    response = predict(input_fn_stream(image), model)\n",
        "    return {\n",
        "        'statusCode': 200,\n",
        "        'body': json.dumps(response)\n",
        "    }\n",
        "\n",
        "def input_fn_stream(image):\n",
        "    image = image[image.find(\",\")+1:]\n",
        "    dec = base64.b64decode(image + \"===\")\n",
        "    byte_array = BytesIO(dec)\n",
        "\n",
        "    im = Image.open(byte_array).resize((640,640))\n",
        "    im = im.convert(\"RGB\")\n",
        "\n",
        "    #https://dev.to/andreygermanov/how-to-create-yolov8-based-object-detection-web-service-using-python-julia-nodejs-javascript-go-and-rust-4o8e#prepare_the_input\n",
        "    # \"We do not need Alpha channel in the image for YOLOv8 predictions. Let's remove it\"\n",
        "    input = np.array(im)\n",
        "    input = input.transpose(2,0,1)\n",
        "    input = input.reshape(1,3,640,640)\n",
        "    input = input/255.0\n",
        "    return torch.Tensor(input)\n",
        "\n",
        "def predict(img_tensor, model):\n",
        "  predict_values = model(img_tensor)\n",
        "  print(predict_values[0].shape)\n",
        "  print('predict_values[0]', predict_values[0])\n",
        "  preds = F.softmax(predict_values, dim=1)\n",
        "  conf_score, indx = torch.max(preds, dim=1)\n",
        "  conf_score = conf_score.cpu().numpy()\n",
        "  indx = indx.cpu().numpy()\n",
        "  predict_class = classes[indx]\n",
        "  response = {}\n",
        "  response['class'] = str(predict_class)\n",
        "  response['confidence'] = str(conf_score)\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "DfcYogpsBYmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the deployed API\n"
      ],
      "metadata": {
        "id": "PCGpmodJAYVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import json\n",
        "\n",
        "path = \"/content/drive/MyDrive/w2/flutter/strawberry-healthy.png\"\n",
        "\n",
        "with open(path, \"rb\") as image_file:\n",
        "  encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "print (len(encoded_string))\n",
        "\n",
        "#url = \"https://zedisfh81b.execute-api.us-east-1.amazonaws.com/detect\"\n",
        "url = \"https://qs9eqe954g.execute-api.us-east-1.amazonaws.com/detect\"\n",
        "data =  {\n",
        "    \"image\": encoded_string\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaIThxtDAum3",
        "outputId": "32bbdce1-5431-4b13-d18e-3605f5a99426"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "844988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "response = requests.post(url, json=data)\n",
        "response"
      ],
      "metadata": {
        "id": "ONKeDHDLA4dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e412eb-9a47-4672-d404-902f905327ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVZ6HQSL7A3P",
        "outputId": "1afeb10b-048a-4a99-c5da-87e944a16c53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Date': 'Wed, 14 Feb 2024 23:18:10 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '227', 'Connection': 'keep-alive', 'Apigw-Requestid': 'TJiE1hRYoAMEJ_A='}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwcqc5ub7v2N",
        "outputId": "9540fe61-6812-4dc5-efb4-f03f6a8d8d91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': \"[['Lettuce Healthy' 'Lettuce Healthy' 'Lettuce Healthy' ...\\n  'Strawberry Healthy' 'Strawberry Healthy' 'Tomato Healthy']]\",\n",
              " 'confidence': '[[0.9999974  1.         1.         ... 1.         1.         0.99998224]]'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d = response.json()\n",
        "print(d.keys())\n",
        "print(d['class'])\n",
        "print(d['confidence'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3qcHIQu75y_",
        "outputId": "15a16bb3-05c9-4d63-bbf0-ceec5681a558"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['class', 'confidence'])\n",
            "[['Lettuce Healthy' 'Lettuce Healthy' 'Lettuce Healthy' ...\n",
            "  'Strawberry Healthy' 'Strawberry Healthy' 'Tomato Healthy']]\n",
            "[[0.9999974  1.         1.         ... 1.         1.         0.99998224]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## references\n",
        "\n",
        "* https://aws.amazon.com/ko/blogs/machine-learning/using-container-images-to-run-pytorch-models-in-aws-lambda/\n",
        "* https://github.com/ahmedbesbes/cartoonify/tree/main"
      ],
      "metadata": {
        "id": "aE8klxb7B0ur"
      }
    }
  ]
}